一、基本思路
    · 因为L0层的sst全都是内存中直接dump到磁盘的，还没有经过任何的sst之间的合并，所以必然存在了重叠区间；
      每一次L0层文件数量或者所有sst文件的总字节数达到了一个阈值的时候，就会触发merge流程，将L0层中相互重叠的sst文件选中(可能会有多个重叠组)；
      然后将L0层的重叠组和L1层中的所有文件进行比较，将L1层中与L0重叠组有重叠的sst页加入到merge group中；
      判断是否重叠只需要比较sst中minKey和maxKey的大小(因为sst文件本身是有序的)，而minKey和maxKey都在TableIndex中被记录，因此这个环节没有什么性能损失；

    · 对于L1到Lmax层的merge过程，会在当前level的size超过阈值时触发，会选择其中fid最小的那个sst文件(因为fid是单调递增的，所以fid最小也就是最旧的sst文件)；
      将fid最小的sst文件和下一层所有的sst文件比较判断是否存在重叠部分，将有重叠的sst文件加入merge组，然后执行多路归并生成新的sst文件

    · 在merge的过程中可能会需要不停的merge同一个key的不同version，所以必须要对至少两个sst文件实行merge排序，由于每个sst文件本身都是有序的，
      不同的key按照升序排序，相同的key按照版本降序排序，因此merge时仅写入第一个key，忽略掉其他相同的key的不同version即可实现compact；

    · 流程：
        1. 定时函数触发检查机制，开始检查是否需要compact；
        2. 判断本轮检查是否已经检查完了所有层，如果全部检查完毕 -->break，如果没有 -->Search(N)
        3. if numSSTable(N) > num阈值 ||  totalSize(N) > size阈值 ，进入下一步，否则 --> break；
		4. if N == 0，计算L0中最大的重叠区间组成的sst MergeGroup；否则，选择L(N)中fid最小的那个sstable文件作为MergeGroup；
		5. 计算MergeGroup中与L(N+1)有重叠的sst文件，并将有重叠的sst也加入到MergeGroup中，生成compact计划；
		6. 基于MergeGroup生成compactIterator：
			· iterator内部会从多个table中获得数据；
			· 比较多个table返回最小的KV Entry；
			· 相同的KV返回最大的版本，并忽略掉其他版本的Key；
			· 记录最后一个key，下一个key如果版本后相等则忽略；
		7. 基于Iterator创建builder对象
		8. 在创建builder的时候，不断判断iterator中是否还有没有遍历过的KV对象，如果有则将其编码放入builder中；
		9. 将builder flush到磁盘中生成一个新的sst文件
		10. 更新manifest文件以及levelManager的索引
		11. 回到第2步，开始检查新的一层
	
	· 问题：
		1. fid最小的sst不一定是能使得MergeGroup最大的sst；
		2. 理论上所有的key最终都会到达Lmax层，为什么不可用直接merge到Lmax以减少写放大的次数；
		3. 已知Level是有界的，Lmax的key最终越来越多，当L6的table越来越多越来越大，性能也会降低；
		4. builder构建的table过多，如果在内存中执行全部的流程，很容易就会发生内存使用负载过大的情况；
		5. 如果流程时，机器down了应该如何处理呢？

	
二、针对于痛点的优化方案
	· L0层中sst是无序的，merge过程会涉及到较多的sst，如何优化读写延迟？
		1. merge时对涉及的sst加读锁，保证在merge时可以对外提供检索服务，
		   而flush到L0的过程都使用append的方式 (在计算MergeGroup的时候不会将新创建的table统计进来，例如 设置一个时间阈值)，因此可以保证时无阻塞的，
		   同时compact结束之后才会加锁删除sst文件，减少了锁粒度，减少了阻塞时间
		   (可以通过mv的方式原子的删除提高并发度)
		
		2. 对L0层的查询最差的情况是可能要遍历所有的sst文件，因此对L0层的sst文件会自身进行compact，
		   可以有效减少L0层的sst文件数量，进而提高查询性能；

	· compact过程需要从Ln到Ln+1，一个有效的key至少需要经历max-1 (6次)次移动，会出现严重的写放大，应该如何解决？
		1. 如果Lmax层没有达到预期的容量，可以直接实现L0到Lmax的compact，进行跨level compact，来减少写放大的情况；

	· Lmax的数据会越来越多，是否会导致数据倾斜？过期的key在L6层是如何被清理的？
		1. 数据达到Lmax层后将无法被压缩到下一层，因此实现Lmax层的自身清洗可以清理Lmax中无效的数据(过期时间)，提高空间利用率和性能；

	· 如何充分发挥ssd的并行度，如何实现并行的compact来提高性能？
		1. level级别和table级别都会持有读写锁，然后维护一个全局的关于sst的状态表，记录灭一个压缩任务的执行状态以及涉及的sst有哪些，
		   在生成压缩计划的时候，检查互斥性，如果当前compact任务涉及到的sst文件与正在执行的其他compact任务没有冲突则可以执行，否则失败；

	· 对于Lx到Ly的压缩，如何选择x与y才能使得整体压缩效益最大化，节省空间提升性能？
		1. L0层会根据sst文件的数量来决定，其他层会根据每个level的去除正在压缩状态的sst文件的总size与每层的期望size的比值作为优先级；
		   而每个level之间的期望size相差一个数量级；也就是说，会优先compact到最大的层减少写放大的次数；
	
	· compact执行过程中，数据库崩溃后数据如何保证一致性？
		1. 只有manifest中记录成功之后，才会向Lx中删除旧的sst，并在Ly中添加新的sst文件；

	· 多个协程执行并行压缩，如果频繁出现并发冲突应该如何解决？
		1. 在多个并发执行的压缩器初始化时，会给定一个随机的时间启动，使得压缩器之间的执行并发量被打散，降低冲突的可能性；

	· 压缩时读取sst文件到内存进行排序是否会造成OOM？
		1. 使用迭代器来从磁盘中逐条的拉取数据到本地，减少内存的使用率，并且可以适当的使用并行预取机制，优化读取的性能；
		2. 允许多个sstable共用一个builder，当一个sstabel的大小以及写到阈值，允许该builder创建一个新的sst继续写入

	· 迭代器的range操作是否会破坏block的缓存？
		1. 迭代过程中正确的识别迭代器的使用场景，跳过set cache过程；


三、逻辑实现